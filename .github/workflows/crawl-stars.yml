name: Crawl stars

on:
  workflow_dispatch:
    inputs:
      target_count:
        description: "Number of repositories to crawl"
        required: false
        default: "100000"

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: github_crawl
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d github_crawl"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5
    env:
      DATABASE_DSN: postgresql://postgres:postgres@localhost:5432/github_crawl
      TARGET_REPOSITORY_COUNT: ${{ inputs.target_count || '100000' }}
      GITHUB_TOKEN: ${{ github.token }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]

      #- name: Run tests
      #  run: pytest

      - name: Prepare database schema
        run: github-crawl init-db --dsn "$DATABASE_DSN"

      - name: Crawl stars
        run: github-crawl crawl-stars --dsn "$DATABASE_DSN" --count "$TARGET_REPOSITORY_COUNT"

      - name: Export results
        run: github-crawl dump --dsn "$DATABASE_DSN" --output repository_stars.csv

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: repository-stars
          path: repository_stars.csv
